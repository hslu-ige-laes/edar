# Data Wrangling
This chapter gives an overview of the most important data manipulation functions used throughout this book.

Experienced readers will find more information about data imports here

- [Introduction to Data Science - Chapter 4 "The tidyverse"](https://rafalab.github.io/dsbook/tidyverse.html#summarizing-data){target="_blank"}

- [Engineering Data Analysis in R - Chapter 3.5 "Data Cleaning"](https://smogdr.github.io/edar_coursebook/rprog2.html#data-cleaning){target="_blank"}

- [Engineering Data Analysis in R - Chapter 3.6 "Piping"](https://smogdr.github.io/edar_coursebook/rprog2.html#piping){target="_blank"}

It is a fact that the data import and manipulation part of analyses often takes more time than the actual analysis or visualization itself. This is because the exchange data formats are not standardized and meters and sensors record at different time intervals. Data quality, missing data, data imputation and data cleansing also play a major role.

\newpage
## Add Metadata for later filtering
Firstly we have to load a dataset into a dataframe:
```{r metadata dataset, warning=FALSE, message=FALSE, collapse = FALSE}
# load data set
df <- read.csv("https://github.com/hslu-ige-laes/edar/raw/master/sampleData/centralOutsideTemp.csv",
               stringsAsFactors=FALSE,
               sep =";")

```

### Year, Month, Day, Day of Week
To e.g. group, filter and aggregate data we need eventually the date splitted up in day, month and year:
```{r metadata date, eval = FALSE}
library(dplyr)
library(lubridate)

df$time <- parse_date_time(df$time, "YmdHMS", tz = "Europe/Zurich")
df$year <- as.Date(cut(df$time, breaks = "year"))
df$month <- as.Date(cut(df$time, breaks = "month"))
df$day <- as.Date(cut(df$time, breaks = "day"))
df$weekday <- wday(df$time,
                   label = TRUE,
                   locale = "English",
                   abbr = TRUE,
                   week_start = getOption("lubridate.week.start", 1))
```

This code first parses the timestamp with a specific timezone. Then three columns are added.

Please note that the month also contains the year and a day. This is useful for a later step where you can group the series afterwards. 

```{r metadata date output, warning=FALSE, message=FALSE, collapse = FALSE}
head(df,2)
tail(df,2)
```

### Hour, Minute, Second
```{r metadata date Hour Min Sec, eval = FALSE}

df$hour <- as.POSIXct(lubridate::floor_date(df$time,"hours"), tz = "Europe/Zurich")
df$minute <- as.POSIXct(lubridate::floor_date(df$time,"minutes"), tz = "Europe/Zurich")
df$second <- as.POSIXct(lubridate::floor_date(df$time,"seconds"), tz = "Europe/Zurich")
```


\newpage
### Season of Year
For some analyses it is useful to color single points of a scatterplot according to the season. For this we need to have the season in a separate column: 

```{r metadata season1, warning=FALSE, message=FALSE, collapse = FALSE}
library(redutils)
# get season from a date
getSeason(as.Date("2019-04-01"))
```

If you want to change the language, you can give the function dedicated names for the season:

```{r metadata season2, warning=FALSE, message=FALSE, collapse = FALSE}
getSeason(as.Date("2019-04-01"),
                  seasonlab = c("Winter","FrÃ¼hling","Sommer","Herbst"))
```

To apply this function to a whole dataframe we can use the dplyr mutate function. The code below creates a new column named "season":

```{r metadata season3, warning=FALSE, message=FALSE, collapse = FALSE}
df <- dplyr::mutate(df, season = getSeason(df$time))
```

```{r metadata season3 output, warning=FALSE, message=FALSE, collapse = FALSE}
head(df,1)
tail(df,1)
```

\newpage
## Manipulating Data Frames
The `dplyr` package from the `tidyverse` introduces functions that perform some of the most common operations when working with data frames and uses names for these functions that are relatively easy to remember.

### Change Row Names
```{r eval=FALSE}
# rename columns
names(df) <- c("timestamp","humidity","temp_c")
```

### Adding a column with `mutate()`
```{r eval=FALSE}
library(dplyr)

# add new column with temperature conversion from celsius to fahrenheit
df <- dplyr::mutate(df, temp_f = temp_c * 1.8 + 32)

# This code does the same, but only with a pipe
df <- df %>% 
  dplyr::mutate(df, temp_f = temp_c * 1.8 + 32)

```

### Subsetting with `filter()`
```{r eval=FALSE}
library(dplyr)

# add new column with temperature conversion from celsius to fahrenheit
df <- filter(df,
             timestamp >= "2020-01-01 00:00:00",
             timestamp <= "2020-12-31 23:45:00")

df.high <- filter(df, temp_c > 30)
```

> Note: Whether you put the whole code on one line or split it after a comma does not have an effect on the computation, it is only more readable when the lines aren't too wide.

\newpage
### Add/remove columns with `select()`
```{r eval=FALSE}
library(dplyr)

# Based on the upper example we remove the celsius column after calculation
df <- select(df, -temp_c)

# Create new data frame
df.new <- select(df, timestamp, temp_f)

# use select() in a so called dplyr pipe
df <- df %>% 
  dplyr::mutate(df, temp_f = temp_c * 1.8 + 32) %>% 
  select(-temp_c)
```

### The pipe `%>%`
With the package `dplyr` we can perform a series of operations, for example select and then filter, by sending the results of one function to another using what is called the pipe operator: `%>%`.

Details can be found in [Introduction to Data Science - Chapter 4.5](https://rafalab.github.io/dsbook/tidyverse.html){target="_blank"}

\newpage
### Wide to Long
```{r rbasics wide2long, warning=FALSE, message=FALSE, collapse = FALSE}
library(tidyr)

# load test data set
df <- read.csv("https://github.com/hslu-ige-laes/edar/raw/master/sampleData/flatTempHum.csv",
               stringsAsFactors=FALSE,
               sep =";")

# create a copy of the dataframe and print the header and the first five line
head(df, 5)

# convert wide to long format
df.long <- as.data.frame(tidyr::pivot_longer(df,
                                             cols = -time,
                                             names_to = "sensor",
                                             values_to = "value",
                                             values_drop_na = TRUE))

# long format
head(df.long, 16)
```

\newpage
### Long to Wide
```{r rbasics long2wide, warning=FALSE, message=FALSE, collapse = FALSE}
# long format
head(df.long)

# convert long table into wide table
df.wide <- as.data.frame(tidyr::pivot_wider(df.long,
                                            names_from = "sensor",
                                            values_from = "value")
                         )

# wide format
head(df.wide)
```

\newpage
### Merge two Dataframes {#DATAWRANGLING-MERGE-TWO-DATAFRAMES}
```{r dataframe merge, warning=FALSE, message=FALSE, collapse = FALSE}
library(dplyr)
library(lubridate)

# read file one and parse dates
dfOutsideTemp <- read.csv("https://github.com/hslu-ige-laes/edar/raw/master/sampleData/centralOutsideTemp.csv",
                          stringsAsFactors=FALSE,
                          sep =";")

dfOutsideTemp$time <- parse_date_time(dfOutsideTemp$time,
                                      orders = "YmdHMS",
                                      tz = "Europe/Zurich")

# read file two and parse dates
dfFlatTempHum <- read.csv("https://github.com/hslu-ige-laes/edar/raw/master/sampleData/flatTempHum.csv",
                          stringsAsFactors=FALSE, sep =";")

dfFlatTempHum$time <- parse_date_time(dfFlatTempHum$time,
                                      order = "YmdHMS",
                                      tz = "Europe/Zurich")

# merge the two files into a new data frame and keep only rows where all values are available
df <- merge(dfOutsideTemp, dfFlatTempHum, by = "time") %>% na.omit()

head(df)
```

\newpage
## Tidy data
The`tidyverse` focus on a consistent way to organise the data which is called `tidy data`. Why should we care? Because a lot of elements in the data analytics process in R like dplyr or ggplot2 work best if the data is in a tidy format.

There are three interrelated rules which make a dataset tidy:
1. Each variable must have its own column.
2. Each observation must have its own row.
3. Each value must have its own cell.

```{r out.width='50%', fig.cap='Three rules make a dataset tidy: variables are in columns, observations are in rows, and values are in cells', echo=FALSE}
knitr::include_graphics("images/tidyData.png")
```

For more info you can have a look at the ['Tidy Data' chapter of the book 'R for Data Science'"](https://r4ds.had.co.nz/tidy-data.html){target="_blank"} and the ['Tidy Data' paper published in the 'Journal of Statistical Software'"](http://www.jstatsoft.org/v59/i10/paper){target="_blank"}

Following examples of how to practically apply these concepts.

### flatTempHum.csv
```{r tidyData11, warning=FALSE, message=FALSE, collapse = FALSE}
library(tidyr)

# load test data set
df <- read.csv("https://github.com/hslu-ige-laes/edar/raw/master/sampleData/flatTempHum.csv",
               stringsAsFactors=FALSE,
               sep =";")

# create a copy of the dataframe and print the header and the first five line
head(df, 5)
```

What needs to be done here to get this data set into a tidy format?
- Firstly each observation should have its own row... well.. not yet. To fulfill that, we have to convert from wide to long.
- Secondly, the variables are `Flat` and `Sensor` which are currently merged together in the column name. That must be separated.

```{r tidyData12, warning=FALSE, message=FALSE, collapse = FALSE}
# convert wide to long format
df.long <- as.data.frame(tidyr::pivot_longer(df,
                                             cols = -time,
                                             names_to = "datapoint",
                                             values_to = "value",
                                             values_drop_na = TRUE))
head(df.long, 16)

# separate datapoint into two columns
df.separated <- df.long %>% separate(col = datapoint, into = c("flat", "sensor"), sep = "_")
head(df.separated, 16)

```

This dataset can now be considered tidy and is ready for further processing.
